# üîß Fix: Erro 404 com Textos Grandes em Rotas Premium

## üî¥ Problema

Usu√°rios premium recebiam **erro 404/413** ao tentar enviar textos muito grandes (> 4.5MB) nas seguintes rotas:
- `/dashboard/corretor-premium` - Corre√ß√£o de texto premium
- `/dashboard/reescrever-premium` - Reescrita de texto premium

### Sintoma:
```
POST /api/correct - 404 Not Found ou 413 FUNCTION_PAYLOAD_TOO_LARGE
POST /api/rewrite - 404 Not Found ou 413 FUNCTION_PAYLOAD_TOO_LARGE
```

Acontecia quando o texto colado ultrapassava ~4.5MB (aproximadamente 2.2 milh√µes de caracteres).

## üîç Causa Raiz

O **Vercel** tem um limite **FIXO E IMUT√ÅVEL de 4.5MB** para o body de requisi√ß√µes em serverless functions.

### ‚ö†Ô∏è Descoberta Importante

**Este limite N√ÉO PODE ser aumentado**, independente do plano Vercel:
- ‚ùå Plano Hobby: 4.5MB (limite de infraestrutura)
- ‚ùå Plano Pro: 4.5MB (mesmo limite)
- ‚ùå Plano Enterprise: 4.5MB (mesmo limite)

### Por que acontece?

√â uma **limita√ß√£o de infraestrutura do Vercel** para serverless functions, n√£o uma configura√ß√£o. Quando o payload ultrapassa 4.5MB, o Vercel retorna:
- **413 FUNCTION_PAYLOAD_TOO_LARGE** (quando detecta antes de chegar no Next.js)
- **404 Not Found** (quando Next.js falha no parsing antes da rota)

### Limites reais:

1. **Vercel Serverless Functions**: 4.5MB (FIXO para todos os planos)
2. **Next.js Server Actions (configur√°vel)**: 2MB ‚Üí 50MB no `next.config.mjs`
   - ‚ö†Ô∏è Mas limitado pelo Vercel a 4.5MB quando em produ√ß√£o

## ‚úÖ Solu√ß√£o

**IMPORTANTE**: N√£o √© poss√≠vel aumentar o limite de 4.5MB no Vercel. A solu√ß√£o √©:

### 1. Aceitar o limite e avisar o usu√°rio

Configurar o Next.js para aceitar at√© 50MB localmente, mas adicionar valida√ß√£o client-side para avisar quando o texto for muito grande para o Vercel.

#### `next.config.mjs` - Aumentar limite local

```javascript
experimental: {
  serverActions: {
    bodySizeLimit: '50mb',  // ‚úÖ Funciona localmente
  },
},
```

**O que isso faz:**
- ‚úÖ Permite desenvolvimento local com textos grandes
- ‚ö†Ô∏è Em produ√ß√£o (Vercel), o limite continua sendo 4.5MB

**Resultado Pr√°tico:**
- **Local (dev)**: at√© 50MB
- **Produ√ß√£o (Vercel)**: at√© 4.5MB (limite de infraestrutura)

### 2. Adicionar valida√ß√£o client-side (IMPLEMENTADO)

Avisar o usu√°rio quando o texto ultrapassar 4MB:

```typescript
// Em PremiumTextCorrectionForm.tsx
const MAX_SIZE_MB = 4 // Limite seguro antes do Vercel recusar
const sizeInMB = new Blob([originalText]).size / 1024 / 1024

if (sizeInMB > MAX_SIZE_MB) {
  toast({
    title: "‚ö†Ô∏è Texto muito grande",
    description: `Seu texto tem ${sizeInMB.toFixed(2)}MB. O limite do Vercel √© 4.5MB. Considere dividir em partes menores.`,
    variant: "destructive",
  })
  return
}
```

## üìä Capacidade Real (TODOS OS PLANOS VERCEL)

| Tipo de Conte√∫do | Tamanho Aproximado |
|------------------|-------------------|
| **Limite do Vercel** | 4.5MB |
| **Texto puro** | ~2.250.000 caracteres |
| **Palavras** | ~375.000 palavras |
| **P√°ginas A4** | ~1.125 p√°ginas |
| **Livros** | ~4-5 livros de 250 p√°ginas |

‚ö†Ô∏è **Importante**: Este limite √© o mesmo para Hobby, Pro e Enterprise!

## üéØ Rotas Afetadas (Agora Corrigidas)

### APIs de Backend:
```
POST /api/correct         (Corre√ß√£o de texto)
POST /api/rewrite         (Reescrita de texto)
POST /api/tone            (Ajuste de tom)
POST /api/ai-detector     (Detector de IA)
POST /api/julinho         (Chat Julinho)
POST /api/mercadopago/*   (Pagamentos)
POST /api/stripe/*        (Pagamentos alternativos)
... todas as outras rotas de API
```

### Componentes Frontend:
```
- PremiumTextCorrectionForm (corretor-premium)
- PremiumRewriteForm (reescrever-premium)
- AIDetectorForm
- JulinhoAssistant
```

## üß™ Como Testar

### Antes da corre√ß√£o:
1. Ir para `/dashboard/corretor-premium`
2. Colar texto > 4MB (2 milh√µes caracteres)
3. Clicar em "Corrigir Texto Premium"
4. ‚ùå Erro 404 no console

### Depois da corre√ß√£o:
1. Ir para `/dashboard/corretor-premium`
2. Colar texto at√© 50MB (25 milh√µes caracteres)
3. Clicar em "Corrigir Texto Premium"
4. ‚úÖ Requisi√ß√£o enviada com sucesso

### Script de Teste R√°pido:

```javascript
// Gerar texto de teste de ~5MB
const largeText = 'Lorem ipsum dolor sit amet. '.repeat(200000) // ~5.4MB
console.log(`Tamanho: ${(new Blob([largeText]).size / 1024 / 1024).toFixed(2)}MB`)

// Enviar para API
fetch('/api/correct', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: largeText,
    isMobile: false,
    isPremium: true
  })
}).then(r => console.log('Status:', r.status))
```

## ‚ö†Ô∏è Considera√ß√µes

### Performance:
- Textos muito grandes demoram mais para processar na IA
- Timeout configurado para 120 segundos (suficiente)
- Cloudflare Workers pode ter seus pr√≥prios limites

### Custos:
- Requisi√ß√µes maiores consomem mais recursos
- API OpenAI cobra por token (textos grandes = mais caro)
- Considerar alertar usu√°rio sobre textos excessivamente grandes

### Limites do Vercel:
- **Hobby/Free**: 4.5MB m√°ximo (nossa config usa 50MB mas Vercel limitar√° a 4.5MB)
- **Pro/Team**: 100MB m√°ximo
- Se estiver no plano Hobby, considerar fazer upgrade ou avisar usu√°rio

## üîß Arquivos Modificados

1. **next.config.mjs**:
   - Atualizado: `bodySizeLimit: '50mb'` (era 2mb)
   - Isso permite que o Next.js aceite payloads maiores

2. **vercel.json**:
   - Nenhuma mudan√ßa necess√°ria
   - O limite √© controlado pelo plano do Vercel (Hobby=4.5MB, Pro=100MB)

## üöÄ Alternativas Para Textos Maiores que 4.5MB

### ‚ùå Upgrade para Vercel Pro N√ÉO resolve
```
Plano Hobby: 4.5MB (limite fixo)
Plano Pro: 4.5MB (mesmo limite fixo)
Plano Enterprise: 4.5MB (mesmo limite fixo)
```

**O limite de 4.5MB √© de INFRAESTRUTURA**, n√£o de plano!

### ‚úÖ Op√ß√£o 1: Client-Side Uploads (Recomendado pelo Vercel)

Em vez de enviar texto pela API, usar upload direto para storage:

```typescript
// Cliente ‚Üí Vercel Blob/S3 (sem passar por serverless function)
const { url } = await upload(largeTextFile, {
  access: 'public',
  handleUploadUrl: '/api/upload-handler',
})

// Ent√£o enviar apenas a URL para a API
await fetch('/api/correct', {
  method: 'POST',
  body: JSON.stringify({ textUrl: url })
})
```

**Benef√≠cios:**
- ‚úÖ Sem limite de tamanho
- ‚úÖ N√£o passa por serverless function
- ‚úÖ Mais r√°pido para arquivos grandes

### ‚úÖ Op√ß√£o 2: Streaming Functions

Usar streaming para responses grandes:

```typescript
// app/api/correct-stream/route.ts
export async function POST(request: Request) {
  const encoder = new TextEncoder()
  const stream = new ReadableStream({
    async start(controller) {
      // Processar e enviar em chunks
      controller.enqueue(encoder.encode('chunk1'))
      controller.enqueue(encoder.encode('chunk2'))
      controller.close()
    }
  })

  return new Response(stream)
}
```

**Benef√≠cios:**
- ‚úÖ Sem limite de response size
- ‚úÖ Feedback progressivo ao usu√°rio

### ‚úÖ Op√ß√£o 3: Chunking (Atual - Melhor para nosso caso)

Dividir texto em partes menores:

```typescript
const MAX_CHUNK_SIZE = 4 * 1024 * 1024 // 4MB
const chunks = splitIntoChunks(largeText, MAX_CHUNK_SIZE)

for (const chunk of chunks) {
  await fetch('/api/correct', {
    method: 'POST',
    body: JSON.stringify({ text: chunk })
  })
}
```

**Benef√≠cios:**
- ‚úÖ Funciona com c√≥digo atual
- ‚úÖ Sem mudan√ßas de infraestrutura
- ‚ö†Ô∏è M√∫ltiplas requisi√ß√µes

## üìù Pr√≥ximos Passos (Opcional)

### 1. Adicionar valida√ß√£o client-side para plano Hobby:
```typescript
// Em PremiumTextCorrectionForm.tsx
const MAX_SIZE_MB = 10 // Avisar se > 10MB
const sizeInMB = new Blob([originalText]).size / 1024 / 1024

if (sizeInMB > MAX_SIZE_MB) {
  toast({
    title: "Texto muito grande",
    description: `Seu texto tem ${sizeInMB.toFixed(2)}MB. Textos grandes podem demorar mais para processar.`,
  })
}
```

### 2. Implementar streaming para textos grandes:
```typescript
// Processar em chunks para textos > 1MB
if (text.length > 1000000) {
  // Dividir em chunks e processar incrementalmente
  // Mostrar progresso ao usu√°rio
}
```

### 3. Adicionar compress√£o:
```typescript
// Usar gzip para comprimir payload antes de enviar
import pako from 'pako'
const compressed = pako.gzip(text)
```

## üéâ Resultado Final

### Todos os Planos Vercel (Hobby, Pro, Enterprise):
‚úÖ **Usu√°rios premium podem enviar textos at√© 4.5MB** (~2.2 milh√µes de caracteres / ~1.125 p√°ginas)
‚úÖ **Valida√ß√£o client-side implementada** para avisar sobre textos muito grandes
‚úÖ **Corre√ß√£o e reescrita funcionam perfeitamente** para textos dentro do limite
‚ö†Ô∏è **Para textos > 4.5MB**: Implementar chunking, client-side uploads ou streaming

### Verdade Sobre o Limite:
- ‚ùå **N√ÉO √© poss√≠vel aumentar** o limite de 4.5MB no Vercel
- ‚ùå **Upgrade para Pro N√ÉO aumenta** esse limite espec√≠fico
- ‚úÖ **√â um limite de infraestrutura** da plataforma Vercel
- ‚úÖ **Mesma limita√ß√£o** em Hobby, Pro e Enterprise

### O que foi feito:
1. **next.config.mjs**: Configurado para 50MB (funciona apenas localmente)
2. **Valida√ß√£o client-side**: Avisar usu√°rio quando texto > 4MB
3. **Documenta√ß√£o**: Esclarecimento sobre limites reais do Vercel
4. **Alternativas documentadas**: Chunking, client-side uploads, streaming

### Recomenda√ß√£o Final:
- ‚úÖ **Para textos at√© 4.5MB**: Solu√ß√£o atual funciona perfeitamente
- ‚ö†Ô∏è **Para textos maiores**: Implementar uma das 3 alternativas documentadas
  1. Client-side uploads (mais recomendado)
  2. Streaming functions
  3. Chunking (mais simples de implementar)

---

**Commit**: `docs: esclarecer limites reais do Vercel (4.5MB fixo em todos os planos)`
**Data**: 2025-01-27
**Issue**: Erro 404/413 com textos grandes em rotas premium
**Limite Real**: 4.5MB (FIXO - todos os planos Vercel)
**Fonte**: [Vercel Docs - Functions Limitations](https://vercel.com/docs/functions/limitations)
